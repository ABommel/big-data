{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parallel Computation\n",
    "\n",
    "## Parallel computers\n",
    "- Multiprocessor/multicore: several processors work on data stored in shared memory\n",
    "- Cluster: several processor/memory units work together by exchanging data over a network\n",
    "- Co-processor: a general-purpose processor delegates specific tasks to a special-purpose processor (GPU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel Programming\n",
    "- Decomposition of the complete task into independent subtasks and the data flow between them.\n",
    "- Distribution of the subtasks over the processors minimizing the total execution time.\n",
    "- For clusters: distribution of the data over the nodes minimizing the communication time.\n",
    "- For multiprocessors: optimization of the memory access patterns minimizing waiting times.\n",
    "- Synchronization of the individual processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import sleep\n",
    "def f(x):\n",
    "    sleep(1)\n",
    "    return x*x\n",
    "L = list(range(8))\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.98 ms, sys: 447 µs, total: 3.43 ms\n",
      "Wall time: 8.01 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time sum(f(x) for x in L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.24 ms, sys: 507 µs, total: 3.74 ms\n",
      "Wall time: 8.01 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time sum(map(f,L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiprocessing \n",
    "\n",
    "`multiprocessing` is a package that supports spawning processes.\n",
    "\n",
    "We can use it to display how many concurrent processes you can launch on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Futures\n",
    "\n",
    "The `concurrent.futures` module provides a high-level interface for asynchronously executing callables.\n",
    "\n",
    "The asynchronous execution can be performed with:\n",
    "- **threads**, using ThreadPoolExecutor, \n",
    "- separate **processes**, using ProcessPoolExecutor. \n",
    "Both implement the same interface, which is defined by the abstract Executor class.\n",
    "\n",
    "`concurrent.futures` can't launch **processes** on windows. Windows users must install \n",
    "[loky](https://github.com/tomMoral/loky)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pmap.py\n"
     ]
    }
   ],
   "source": [
    "%%file pmap.py\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from time import sleep, time\n",
    "\n",
    "def f(x):\n",
    "    sleep(1)\n",
    "    return x*x\n",
    "\n",
    "L = list(range(8))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    begin = time()\n",
    "    with ProcessPoolExecutor() as pool:\n",
    "\n",
    "        result = sum(pool.map(f, L))\n",
    "    end = time()\n",
    "    \n",
    "    print(f\"result = {result} and time = {end-begin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# \n",
    "# python pmap.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- `ProcessPoolExecutor` launches one slave process per physical core on the computer. \n",
    "- `pool.map` divides the input list into chunks and puts the tasks (function + chunk) on a queue.\n",
    "- Each slave process takes a task (function + a chunk of data), runs map(function, chunk), and puts the result on a result list.\n",
    "- `pool.map` on the master process waits until all tasks are handled and returns the concatenation of the result lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "CPU times: user 2.71 ms, sys: 3.85 ms, total: 6.56 ms\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "with ThreadPoolExecutor() as pool:\n",
    "\n",
    "    results = sum(pool.map(f, L))\n",
    "    \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thread and Process: Differences\n",
    "\n",
    "- A **process** is an instance of a running program. \n",
    "- **Process** may contain one or more **threads**, but a **thread** cannot contain a **process**.\n",
    "- **Process** has a self-contained execution environment. It has its own memory space. \n",
    "- Application running on your computer may be a set of cooperating **processes**.\n",
    "- **Process** don't share its memory, communication between **processes** implies data serialization.\n",
    "\n",
    "- A **thread** is made of and exist within a **process**; every **process** has at least one **thread**. \n",
    "- Multiple **threads** in a **process** share resources, which helps in efficient communication between **threads**.\n",
    "- **Threads** can be concurrent on a multi-core system, with every core executing the separate **threads** simultaneously.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Global Interpreter Lock (GIL)\n",
    "\n",
    "- The Python interpreter is not thread safe.\n",
    "- A few critical internal data structures may only be accessed by one thread at a time. Access to them is protected by the GIL.\n",
    "- Attempts at removing the GIL from Python have failed until now. The main difficulty is maintaining the C API for extension modules.\n",
    "- Multiprocessing avoids the GIL by having separate processes which each have an independent copy of the interpreter data structures.\n",
    "- The price to pay: serialization of tasks, arguments, and results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Weighted mean and Variance\n",
    "\n",
    "### Exercise 6.1\n",
    "\n",
    "Use `ThreadPoolExecutor` to parallelized functions written in notebook 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [5, 1, 2, 3, 1, 2, 5, 4]\n",
    "P = [0.05, 0.05, 0.15, 0.05, 0.15, 0.2, 0.1, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add, mul\n",
    "from functools import reduce\n",
    "from concurrent.futures import ThreadPoolExecutor as pool\n",
    "\n",
    "def weighted_mean( X, P):\n",
    "    \n",
    "    with pool() as p:\n",
    "        w1 = p.map(mul, X, P)\n",
    "    \n",
    "    return reduce(add,w1)\n",
    "\n",
    "weighted_mean(X,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9600000000000017"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def variance(X, P):\n",
    "    mu = weighted_mean(X,P)\n",
    "    with pool() as p:\n",
    "        w2 = p.map(lambda x,p:p*x*x, X, P)\n",
    "    return reduce(add,w2) - mu**2\n",
    "\n",
    "variance(X, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(X)\n",
    "p = np.array(P)\n",
    "np.average( x, weights=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9600000000000017"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var =np.sum(p*x**2) - np.average( x, weights=p)**2\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from itertools import chain\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "def mapper(filename):\n",
    "    \" split text to list of key/value pairs (word,1)\"\n",
    "    with open(filename) as f:\n",
    "        data = f.read()\n",
    "        \n",
    "    data = data.strip().replace(\".\",\"\").lower().split()\n",
    "        \n",
    "    return sorted([(w,1) for w in data])\n",
    "\n",
    "\n",
    "def partitioner(mapped_values):\n",
    "    \"\"\" get lists from mapper and create a dict with\n",
    "    (word,[1,1,1])\"\"\"\n",
    "    \n",
    "    res = defaultdict(list)\n",
    "    for w, c in mapped_values:\n",
    "        res[w].append(c)\n",
    "        \n",
    "    return res.items()\n",
    "\n",
    "\n",
    "def reducer( item ):\n",
    "    \"\"\" Compute words occurences from dict computed\n",
    "    by partioner\n",
    "    \"\"\"\n",
    "    w, v = item\n",
    "    return (w,len(v))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "## Parallel map\n",
    "\n",
    "\n",
    "- Let's improve the `mapper` function by print out inside the function the current process name. \n",
    "\n",
    "*Example*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ForkProcess-1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ForkProcess-2"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "#from loky import ProcessPoolExecutor \n",
    "def process_name(n):\n",
    "    \" prints out the current process name \"\n",
    "    print(mp.current_process().name)\n",
    "\n",
    "with ProcessPoolExecutor() as e:\n",
    "    _ = e.map(process_name, range(mp.cpu_count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 6.2\n",
    "\n",
    "- Modify the mapper function by adding this print."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(filename):\n",
    "    \" split text to list of key/value pairs (word,1)\"\n",
    "    \n",
    "    print(f\"{mp.current_process().name} : {filename}\")\n",
    "    with open(filename) as f:\n",
    "        data = f.read()\n",
    "        \n",
    "    data = data.strip().replace(\".\",\"\").lower().split()\n",
    "        \n",
    "    return sorted([(w,1) for w in data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel reduce\n",
    "\n",
    "- For parallel reduce operation, data must be aligned in a container. We already created a `partitioner` function that returns this container.\n",
    "\n",
    "### Exercise 6.3\n",
    "\n",
    "Write a parallel program that uses the three functions above using `ProcessPoolExecutor`. It reads all the \"sample\\*.txt\" files. Map and reduce steps are parallel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def wordcount(files):\n",
    "    \n",
    "    with ThreadPoolExecutor() as e:\n",
    "    \n",
    "        mapped_values = e.map(mapper, files)\n",
    "        partioned_values = partitioner(chain(*mapped_values))\n",
    "        occurences = e.map(reducer, partioned_values)\n",
    "    \n",
    "    return sorted(occurences,\n",
    "                 key=itemgetter(1),\n",
    "                 reverse=True)\n",
    "    \n",
    "files = glob(\"sample*.txt\")  \n",
    "wordcount(files)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Increase volume of data\n",
    "\n",
    "*Due to the proxy, code above is not runnable on workstations*\n",
    "\n",
    "### Getting the data\n",
    "\n",
    "- [The Latin Library](http://www.thelatinlibrary.com/) contains a huge collection of freely accessible Latin texts. We get links on the Latin Library's homepage ignoring some links that are not associated with a particular author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  # web scraping library\n",
    "from urllib.request import *\n",
    "\n",
    "base_url = \"http://www.thelatinlibrary.com/\"\n",
    "home_content = urlopen(base_url)\n",
    "\n",
    "soup = BeautifulSoup(home_content, \"lxml\")\n",
    "author_page_links = soup.find_all(\"a\")\n",
    "author_pages = [ap[\"href\"] for i, ap in enumerate(author_page_links) if i < 49]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generate html links\n",
    "\n",
    "- Create a list of all links pointing to Latin texts. The Latin Library uses a special format which makes it easy to find the corresponding links: All of these links contain the name of the text author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ap_content = list()\n",
    "for ap in author_pages:\n",
    "    ap_content.append(urlopen(base_url + ap))\n",
    "\n",
    "book_links = list()\n",
    "for path, content in zip(author_pages, ap_content):\n",
    "    author_name = path.split(\".\")[0]\n",
    "    ap_soup = BeautifulSoup(content, \"lxml\")\n",
    "    book_links += ([link for link in ap_soup.find_all(\"a\", {\"href\": True}) if author_name in link[\"href\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Download webpages content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 1 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 2 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 3 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 4 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 5 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 6 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 7 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 8 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 9 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 10 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 11 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 12 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 13 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 14 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 15 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 16 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 17 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 18 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 19 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 20 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 21 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 22 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 23 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 24 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 25 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 26 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 27 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 28 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 29 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 30 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 31 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 32 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 33 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 34 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 35 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 36 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 37 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 38 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 39 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 40 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 41 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 42 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 43 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 44 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 45 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 46 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 47 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 48 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 49 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 50 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 51 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 52 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 53 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 54 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 55 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 56 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 57 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 58 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 59 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 60 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 61 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 62 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 63 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 64 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 65 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 66 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 67 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 68 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 69 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 70 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 71 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 72 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 73 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 74 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 75 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 76 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 77 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 78 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 79 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 80 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 81 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 82 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 83 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 84 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 85 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 86 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 87 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 88 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 89 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 90 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 91 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 92 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 93 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 94 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 95 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 96 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 97 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 98 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 99 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 100 of 100\r"
     ]
    }
   ],
   "source": [
    "from urllib.error import HTTPError\n",
    "\n",
    "num_pages = 100\n",
    "\n",
    "for i, bl in enumerate(book_links[:num_pages]):\n",
    "    print(\"Getting content \" + str(i + 1) + \" of \" + str(num_pages), end=\"\\r\", flush=True)\n",
    "    try:\n",
    "        content = urlopen(base_url + bl[\"href\"]).read()\n",
    "        with open(f\"book-{i:03d}.dat\",\"wb\") as f:\n",
    "            f.write(content)\n",
    "    except HTTPError as err:\n",
    "        print(\"Unable to retrieve \" + bl[\"href\"] + \".\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extract data files\n",
    "\n",
    "- I already put the content of pages in files named book-*.txt\n",
    "- You can extract data from the archive by running the cell below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```py\n",
    "import os  # library to get directory and file paths\n",
    "import tarfile # this module makes possible to read and write tar archives\n",
    "\n",
    "def extract_data():\n",
    "    datadir = os.path.join('data','latinbooks')\n",
    "    if not os.path.exists(datadir):\n",
    "       print(\"Extracting data...\")\n",
    "       tar_path = os.path.join('data', 'latinbooks.tgz')\n",
    "       with tarfile.open(tar_path, mode='r:gz') as books:\n",
    "          books.extractall('data')\n",
    "            \n",
    "extract_data() # this function call will extract text files in data/latinbooks\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Read data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "files = glob('book*.dat')\n",
    "texts = list()\n",
    "for file in files:\n",
    "    with open(file,'rb') as f:\n",
    "        text = f.read()\n",
    "    texts.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extract the text from html and split the text at periods to convert it into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 2 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 3 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 4 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 5 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 6 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 7 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 8 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 9 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 10 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 11 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 12 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 13 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 14 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 15 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 16 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 17 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 18 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 19 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 20 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 21 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 22 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 23 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 24 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 25 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 26 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 27 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 28 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 29 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 30 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 31 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 32 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 33 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 34 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 35 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 36 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 37 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 38 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 39 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 40 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 41 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 42 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 43 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 44 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 45 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 46 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 47 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 48 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 49 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 50 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 51 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 52 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 53 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 54 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 55 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 56 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 57 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 58 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 59 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 60 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 61 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 62 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 63 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 64 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 65 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 66 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 67 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 68 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 69 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 70 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 71 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 72 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 73 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 74 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 75 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 76 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 77 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 78 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 79 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 80 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 81 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 82 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 83 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 84 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 85 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 86 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 87 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 88 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 89 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 90 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 91 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 92 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 93 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 94 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 95 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 96 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 97 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 98 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 99 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 100 of 100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sed nimirum nihil fortuna rennuente licet homini natu dexterum provenire nec consilio prudenti vel remedio sagaci divinae providentiae fatalis dispositio subuerti vel reformari potest\n",
      "\n",
      "CPU times: user 1.74 s, sys: 49.1 ms, total: 1.79 s\n",
      "Wall time: 1.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "sentences = list()\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    print(\"Document \" + str(i + 1) + \" of \" + str(len(texts)), end=\"\\r\", flush=True)\n",
    "    textSoup = BeautifulSoup(text, \"lxml\")\n",
    "    paragraphs = textSoup.find_all(\"p\", attrs={\"class\":None})\n",
    "    prepared = (\"\".join([p.text.strip().lower() for p in paragraphs[1:-1]]))\n",
    "    for t in prepared.split(\".\"):\n",
    "        part = \"\".join([c for c in t if c.isalpha() or c.isspace()])\n",
    "        sentences.append(part.strip())\n",
    "\n",
    "# print first and last sentence to check the results\n",
    "print(sentences[0])\n",
    "print(sentences[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 6.4\n",
    "\n",
    "Parallelize this last process using `concurrent.futures`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sed nimirum nihil fortuna rennuente licet homini natu dexterum provenire nec consilio prudenti vel remedio sagaci divinae providentiae fatalis dispositio subuerti vel reformari potest\n",
      "\n",
      "CPU times: user 2.68 s, sys: 1.11 s, total: 3.79 s\n",
      "Wall time: 2.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor as pool\n",
    "\n",
    "def sentence_mapper(text):\n",
    "    sentences = list()\n",
    "    textSoup = BeautifulSoup(text, \"lxml\")\n",
    "    paragraphs = textSoup.find_all(\"p\", attrs={\"class\":None})\n",
    "    prepared = (\"\".join([p.text.strip().lower() for p in paragraphs[1:-1]]))\n",
    "    for t in prepared.split(\".\"):\n",
    "        part = \"\".join([c for c in t if c.isalpha() or c.isspace()])\n",
    "        sentences.append(part.strip())\n",
    "    return sentences\n",
    "\n",
    "# parallel map\n",
    "with pool(4) as p:\n",
    "    \n",
    "    mapped_sentences = p.map(sentence_mapper, texts)\n",
    "\n",
    "# reduce\n",
    "sentences = reduce(add, mapped_sentences )\n",
    "\n",
    "# print first and last sentence to check the results\n",
    "print(sentences[0])\n",
    "print(sentences[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "- [Using Conditional Random Fields and Python for Latin word segmentation](https://medium.com/@felixmohr/using-python-and-conditional-random-fields-for-latin-word-segmentation-416ca7a9e513)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "jupytext": {
   "cell_metadata_json": true
  },
  "kernelspec": {
   "display_name": "big-data",
   "language": "python",
   "name": "big-data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
