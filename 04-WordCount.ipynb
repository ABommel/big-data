{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wordcount\n",
    "\n",
    "- [Wikipedia](https://en.wikipedia.org/wiki/Word_count)\n",
    "\n",
    "- Word count example reads text files and counts how often words occur. \n",
    "- Word count is commonly used by translators to determine the price for the translation job.\n",
    "- This is the \"Hello World\" program of Big Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some recommendations:\n",
    "- *Don't google too much, ask me or use the python documentation through `help` function.*\n",
    "- *Do not try to find a clever or optimized solution, do something that works before.*\n",
    "- *Please don't get the solution from your colleagues*\n",
    "- *Notebooks will be updated next week with solutions*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create sample text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from lorem import text\n",
    "\n",
    "with open(\"sample.txt\", \"w\") as f:\n",
    "    for i in range(10000):\n",
    "        f.write(text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4.1\n",
    "\n",
    "Write a python program that counts the number of lines, words and characters in that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   70202  2021479 14280294 sample.txt\n",
      "14M\tsample.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wc sample.txt\n",
    "du -h sample.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute number of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70203"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"sample.txt\") as f:\n",
    "    lines = list(f)\n",
    "\n",
    "nlines = len(lines)\n",
    "nlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021479"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwords = sum([len(line.split()) for line in lines])\n",
    "nwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12223715"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nchars = 0\n",
    "for line in lines:\n",
    "    words = line.split()\n",
    "    nchars += sum([len(word) for word in line.split()])\n",
    "        \n",
    "nchars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `set` gives the list of unique elements from words list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Consectetur',\n",
       " 'Etincidunt',\n",
       " 'Numquam',\n",
       " 'Voluptatem',\n",
       " 'adipisci',\n",
       " 'dolor',\n",
       " 'dolor.',\n",
       " 'dolore.',\n",
       " 'dolorem',\n",
       " 'est',\n",
       " 'etincidunt',\n",
       " 'ipsum',\n",
       " 'labore',\n",
       " 'magnam',\n",
       " 'magnam.',\n",
       " 'neque',\n",
       " 'numquam',\n",
       " 'sed',\n",
       " 'sit',\n",
       " 'tempora',\n",
       " 'ut',\n",
       " 'velit.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = set(words)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4.2\n",
    "\n",
    "Create a function called `map_words` that take a file name as argument and return a lists containing all words as items.\n",
    "\n",
    "```pytb\n",
    "map_words(\"sample.txt\")[:5] # first five words\n",
    "['adipisci', 'adipisci', 'adipisci', 'adipisci', 'adipisci']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adipisci', 'adipisci', 'adipisci', 'adipisci', 'adipisci']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_words(filename):\n",
    "    \"\"\" take a file name as argument and return a \n",
    "    lists containing all words as item\n",
    "    \"\"\"\n",
    "    with open(filename) as f:\n",
    "        data = f.read().lower().replace('.',' ')\n",
    "        \n",
    "    return sorted(data.split())\n",
    "\n",
    "map_words(\"sample.txt\")[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sorting a dictionary by value\n",
    "\n",
    "By default, if you use `sorted` function on a `dict`, it will use keys to sort it.\n",
    "To sort by values, you can use [operator](https://docs.python.org/3.6/library/operator.html).itemgetter(1)\n",
    "Return a callable object that fetches item from its operand using the operandâ€™s `__getitem__(` method. It could be used to sort results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'orange': 1, 'banana': 2, 'apple': 3, 'pear': 5}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "fruits = [('apple', 3), ('banana', 2), ('pear', 5), ('orange', 1)]\n",
    "getcount = operator.itemgetter(1)\n",
    "dict(sorted(fruits, key=getcount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`sorted` function has also a `reverse` optional argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pear': 5, 'apple': 3, 'banana': 2, 'orange': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sorted(fruits, key=getcount, reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4.3\n",
    "\n",
    "Create a function `reduce` to reduce the list of words returned by `map_words` and return a dictionary containing all words as keys and number of occurrences as values.\n",
    "\n",
    "```pybt\n",
    "wordcount('sample.txt')\n",
    "{'tempora': 2, 'non': 1, 'quisquam': 1, 'amet': 1, 'sit': 1}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'est': 75639,\n",
       " 'ut': 75484,\n",
       " 'voluptatem': 75479,\n",
       " 'sit': 75425,\n",
       " 'dolor': 75424,\n",
       " 'amet': 75414,\n",
       " 'etincidunt': 75403,\n",
       " 'quaerat': 75363,\n",
       " 'aliquam': 75359,\n",
       " 'dolorem': 75301,\n",
       " 'neque': 75284,\n",
       " 'porro': 75269,\n",
       " 'modi': 75258,\n",
       " 'dolore': 75254,\n",
       " 'velit': 75229,\n",
       " 'quiquia': 75223,\n",
       " 'eius': 75217,\n",
       " 'labore': 75163,\n",
       " 'numquam': 75153,\n",
       " 'quisquam': 75130,\n",
       " 'tempora': 75089,\n",
       " 'adipisci': 75077,\n",
       " 'sed': 75067,\n",
       " 'ipsum': 75023,\n",
       " 'magnam': 74989,\n",
       " 'non': 74968,\n",
       " 'consectetur': 74794}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reduce(sorted_words):\n",
    "    \" Compute word occurences from sorted list of words\"\n",
    "    \n",
    "    res = {}\n",
    "    current_word = None\n",
    "    for word in sorted_words:\n",
    "        if word == current_word:\n",
    "            res[word] += 1\n",
    "        else:\n",
    "            res[word] = 1\n",
    "            current_word = word\n",
    "    return dict(sorted(res.items(), key=lambda v:v[1], reverse=True))\n",
    "\n",
    "reduce(map_words(\"sample.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `reduce` function using python exception KeyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'est': 75639,\n",
       " 'ut': 75484,\n",
       " 'voluptatem': 75479,\n",
       " 'sit': 75425,\n",
       " 'dolor': 75424,\n",
       " 'amet': 75414,\n",
       " 'etincidunt': 75403,\n",
       " 'quaerat': 75363,\n",
       " 'aliquam': 75359,\n",
       " 'dolorem': 75301,\n",
       " 'neque': 75284,\n",
       " 'porro': 75269,\n",
       " 'modi': 75258,\n",
       " 'dolore': 75254,\n",
       " 'velit': 75229,\n",
       " 'quiquia': 75223,\n",
       " 'eius': 75217,\n",
       " 'labore': 75163,\n",
       " 'numquam': 75153,\n",
       " 'quisquam': 75130,\n",
       " 'tempora': 75089,\n",
       " 'adipisci': 75077,\n",
       " 'sed': 75067,\n",
       " 'ipsum': 75023,\n",
       " 'magnam': 74989,\n",
       " 'non': 74968,\n",
       " 'consectetur': 74794}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reduce(sorted_words):\n",
    "    \" Compute word occurences from sorted list of words\"\n",
    "\n",
    "    res = {}\n",
    "    for word in sorted_words:\n",
    "        try:\n",
    "            res[word] += 1\n",
    "        except KeyError:\n",
    "            res[word] = 1\n",
    "            \n",
    "    return dict(sorted(res.items(), key=lambda v:v[1], reverse=True))\n",
    "\n",
    "reduce(map_words(\"sample.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You probably notice that this simple function is not easy to implement. Python standard library provides some features that can help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Container datatypes\n",
    "\n",
    "`collection` module implements specialized container datatypes providing alternatives to Pythonâ€™s general purpose built-in containers, `dict`, `list`, `set`, and `tuple`.\n",
    "\n",
    "- `defaultdict` :\tdict subclass that calls a factory function to supply missing values\n",
    "- `Counter`\t: dict subclass for counting hashable objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### defaultdict\n",
    "\n",
    "When you implement the `wordcount` function you probably had some problem to append key-value pair to your `dict`. If you try to change the value of a key that is not present \n",
    "in the dict, the key is not automatically created.\n",
    "\n",
    "You can use a `try-except` flow but the `defaultdict` could be a solution. This container is a `dict` subclass that calls a factory function to supply missing values.\n",
    "For example, using list as the default_factory, it is easy to group a sequence of key-value pairs into a dictionary of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yellow': [1, 3], 'blue': [2, 4], 'red': [1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)]\n",
    "d = defaultdict(list)\n",
    "for k, v in s:\n",
    "    d[k].append(v)\n",
    "\n",
    "dict(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4.4\n",
    "\n",
    "- Modify the `reduce` function you wrote above by using a defaultdict with the most suitable factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'est': 75639,\n",
       " 'ut': 75484,\n",
       " 'voluptatem': 75479,\n",
       " 'sit': 75425,\n",
       " 'dolor': 75424,\n",
       " 'amet': 75414,\n",
       " 'etincidunt': 75403,\n",
       " 'quaerat': 75363,\n",
       " 'aliquam': 75359,\n",
       " 'dolorem': 75301,\n",
       " 'neque': 75284,\n",
       " 'porro': 75269,\n",
       " 'modi': 75258,\n",
       " 'dolore': 75254,\n",
       " 'velit': 75229,\n",
       " 'quiquia': 75223,\n",
       " 'eius': 75217,\n",
       " 'labore': 75163,\n",
       " 'numquam': 75153,\n",
       " 'quisquam': 75130,\n",
       " 'tempora': 75089,\n",
       " 'adipisci': 75077,\n",
       " 'sed': 75067,\n",
       " 'ipsum': 75023,\n",
       " 'magnam': 74989,\n",
       " 'non': 74968,\n",
       " 'consectetur': 74794}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def reduce(sorted_words):\n",
    "    \" Reduce version using defaultdict, we use factory `int`\"\n",
    "    res = defaultdict(int)\n",
    "    for word in sorted_words:\n",
    "        res[word] += 1\n",
    "            \n",
    "    return dict(sorted(res.items(), key=lambda v:v[1], reverse=True))\n",
    "\n",
    "reduce(map_words(\"sample.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Counter\n",
    "\n",
    "A Counter is a dict subclass for counting hashable objects. It is an unordered collection where elements are stored as dictionary keys and their counts are stored as dictionary values. Counts are allowed to be any integer value including zero or negative counts.\n",
    "\n",
    "Elements are counted from an iterable or initialized from another mapping (or counter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r': 23, 'g': 13, 'b': 23}\n",
      "0\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "violet = dict(r=23,g=13,b=23)\n",
    "print(violet)\n",
    "cnt = Counter(violet)  # or Counter(r=238, g=130, b=238)\n",
    "print(cnt['c'])\n",
    "print(cnt['r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r r r r r r r r r r r r r r r r r r r r r r r g g g g g g g g g g g g g b b b b b b b b b b b b b b b b b b b b b b b\n"
     ]
    }
   ],
   "source": [
    "print(*cnt.elements())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('r', 23), ('b', 23)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.most_common(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([23, 13, 23])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4.5\n",
    "\n",
    "Use a `Counter` object to count words occurences in the sample text file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'est': 75639,\n",
       " 'ut': 75484,\n",
       " 'voluptatem': 75479,\n",
       " 'sit': 75425,\n",
       " 'dolor': 75424,\n",
       " 'amet': 75414,\n",
       " 'etincidunt': 75403,\n",
       " 'quaerat': 75363,\n",
       " 'aliquam': 75359,\n",
       " 'dolorem': 75301,\n",
       " 'neque': 75284,\n",
       " 'porro': 75269,\n",
       " 'modi': 75258,\n",
       " 'dolore': 75254,\n",
       " 'velit': 75229,\n",
       " 'quiquia': 75223,\n",
       " 'eius': 75217,\n",
       " 'labore': 75163,\n",
       " 'numquam': 75153,\n",
       " 'quisquam': 75130,\n",
       " 'tempora': 75089,\n",
       " 'adipisci': 75077,\n",
       " 'sed': 75067,\n",
       " 'ipsum': 75023,\n",
       " 'magnam': 74989,\n",
       " 'non': 74968,\n",
       " 'consectetur': 74794}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def wordcounter(filename):\n",
    "    \n",
    "    \" Wordcount function using the Counter type from collections\"\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        data = f.read()\n",
    "    \n",
    "    c = Counter(data.lower().replace(\".\",\" \").split())\n",
    "    return dict(c.most_common())\n",
    "\n",
    "wordcounter(\"sample.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The Counter class is similar to bags or multisets in some Python libraries or other languages. We will see later how to use Counter-like objects in a parallel context. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Process multiple files\n",
    "\n",
    "- Create several files containing `lorem` text named 'sample01.txt', 'sample02.txt'...\n",
    "- If you process these files you return multiple dictionaries.\n",
    "- You have to loop over them to sum occurences and return the resulted dict. To iterate on specific mappings, Python standard library provides some useful features in `itertools` module.\n",
    "- [itertools.chain(*mapped_values)](https://docs.python.org/3.6/library/itertools.html#itertools.chain) could be used for treating consecutive sequences as a single sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'orange': 1,\n",
       " 'spinach': 1,\n",
       " 'banana': 2,\n",
       " 'endive': 2,\n",
       " 'apple': 3,\n",
       " 'carrot': 4,\n",
       " 'pear': 5,\n",
       " 'celery': 5}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools, operator\n",
    "fruits = [('apple', 3), ('banana', 2), ('pear', 5), ('orange', 1)]\n",
    "vegetables = [('endive', 2), ('spinach', 1), ('celery', 5), ('carrot', 4)]\n",
    "getcount = operator.itemgetter(1)\n",
    "dict(sorted(itertools.chain(fruits,vegetables), key=getcount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4.6\n",
    "\n",
    "- Write the program that creates files, processes and use `itertools.chain` to get the merged word count dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lorem\n",
    "\n",
    "for i in range(4): # write 4 sample text files\n",
    "    with open(f\"sample{i:02d}.txt\", \"w\") as f:\n",
    "        f.write(lorem.text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "samples = glob(\"*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'voluptatem': 30,\n",
       " 'amet': 26,\n",
       " 'labore': 24,\n",
       " 'ipsum': 23,\n",
       " 'sed': 23,\n",
       " 'etincidunt': 22,\n",
       " 'neque': 22,\n",
       " 'consectetur': 21,\n",
       " 'dolore': 21,\n",
       " 'tempora': 21,\n",
       " 'quaerat': 20,\n",
       " 'quiquia': 20,\n",
       " 'numquam': 19,\n",
       " 'eius': 18,\n",
       " 'dolor': 17,\n",
       " 'magnam': 17,\n",
       " 'non': 17,\n",
       " 'quisquam': 17,\n",
       " 'adipisci': 16,\n",
       " 'est': 16,\n",
       " 'porro': 16,\n",
       " 'sit': 16,\n",
       " 'modi': 14,\n",
       " 'ut': 14,\n",
       " 'velit': 14,\n",
       " 'aliquam': 13,\n",
       " 'dolorem': 13}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "words1 = map_words(\"sample01.txt\")\n",
    "words2 = map_words(\"sample02.txt\")\n",
    "\n",
    "reduce(chain(words1,words2)) # word count on two files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wordcount on a list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amet': 101,\n",
       " 'consectetur': 101,\n",
       " 'ipsum': 98,\n",
       " 'neque': 98,\n",
       " 'est': 96,\n",
       " 'tempora': 96,\n",
       " 'labore': 95,\n",
       " 'voluptatem': 94,\n",
       " 'quisquam': 92,\n",
       " 'sit': 92,\n",
       " 'quiquia': 87,\n",
       " 'dolore': 85,\n",
       " 'ut': 85,\n",
       " 'velit': 85,\n",
       " 'sed': 84,\n",
       " 'adipisci': 82,\n",
       " 'eius': 82,\n",
       " 'quaerat': 81,\n",
       " 'etincidunt': 78,\n",
       " 'porro': 78,\n",
       " 'dolorem': 77,\n",
       " 'dolor': 76,\n",
       " 'modi': 76,\n",
       " 'non': 75,\n",
       " 'numquam': 74,\n",
       " 'aliquam': 67,\n",
       " 'magnam': 66}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from glob import glob\n",
    "\n",
    "reduce(chain(*[map_words(file) for file in glob(\"sample0*.txt\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4.7\n",
    "\n",
    "- Create the `wordcount` function in order to accept several files as arguments and\n",
    "return the result dict.\n",
    "\n",
    "```\n",
    "wordcount(file1, file2, file3, ...)\n",
    "```\n",
    "\n",
    "[Hint: arbitrary argument lists](https://docs.python.org/3/tutorial/controlflow.html#arbitrary-argument-lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example of use of arbitrary argument list and arbitrary named arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[1, 2]\n",
      "bonjour\n",
      "{'x': 4, 'y': 'y'}\n"
     ]
    }
   ],
   "source": [
    "def func( *args, **kwargs):\n",
    "    for arg in args:\n",
    "        print(arg)\n",
    "        \n",
    "    print(kwargs)\n",
    "        \n",
    "func( \"3\", [1,2], \"bonjour\", x = 4, y = \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amet': 101,\n",
       " 'consectetur': 101,\n",
       " 'ipsum': 98,\n",
       " 'neque': 98,\n",
       " 'est': 96,\n",
       " 'tempora': 96,\n",
       " 'labore': 95,\n",
       " 'voluptatem': 94,\n",
       " 'quisquam': 92,\n",
       " 'sit': 92,\n",
       " 'quiquia': 87,\n",
       " 'dolore': 85,\n",
       " 'ut': 85,\n",
       " 'velit': 85,\n",
       " 'sed': 84,\n",
       " 'adipisci': 82,\n",
       " 'eius': 82,\n",
       " 'quaerat': 81,\n",
       " 'etincidunt': 78,\n",
       " 'porro': 78,\n",
       " 'dolorem': 77,\n",
       " 'dolor': 76,\n",
       " 'modi': 76,\n",
       " 'non': 75,\n",
       " 'numquam': 74,\n",
       " 'aliquam': 67,\n",
       " 'magnam': 66}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from glob import glob\n",
    "\n",
    "def wordcount(*args): # arbitrary argument list\n",
    "    \n",
    "    # MAP \n",
    "    mapped_values = []\n",
    "    for filename in args:\n",
    "        with open(filename) as f:\n",
    "            data = f.read()\n",
    "        words = data.lower().replace('.','').strip().split()\n",
    "        mapped_values.append(sorted(words))\n",
    "    \n",
    "    # REDUCE \n",
    "    return reduce(chain(*mapped_values))\n",
    "\n",
    "wordcount(*glob(\"sample0*.txt\"))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "big-data",
   "language": "python",
   "name": "big-data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
