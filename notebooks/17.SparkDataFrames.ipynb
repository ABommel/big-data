{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark DataFrames\n",
    "\n",
    "- Enable wider audiences beyond “Big Data” engineers to leverage the power of distributed processing\n",
    "- Inspired by data frames in R and Python (Pandas)\n",
    "- Designed from the ground-up to support modern big\n",
    "data and data science applications\n",
    "- Extension to the existing RDD API\n",
    "\n",
    "## References\n",
    "- [Spark SQL, DataFrames and Datasets Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html)\n",
    "- [Introduction to DataFrames - Python](https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html)\n",
    "- [PySpark Cheat Sheet: Spark DataFrames in Python](https://www.datacamp.com/community/blog/pyspark-sql-cheat-sheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames are :\n",
    "- The preferred abstraction in Spark\n",
    "- Strongly typed collection of distributed elements \n",
    "- Built on Resilient Distributed Datasets (RDD)\n",
    "- Immutable once constructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Dataframes you can :\n",
    "- Track lineage information to efficiently recompute lost data \n",
    "- Enable operations on collection of elements in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You construct DataFrames\n",
    "- by parallelizing existing collections (e.g., Pandas DataFrames) \n",
    "- by transforming an existing DataFrames\n",
    "- from files in HDFS or any other storage system (e.g., Parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "- Ability to scale from kilobytes of data on a single laptop to petabytes on a large cluster\n",
    "- Support for a wide array of data formats and storage systems\n",
    "- Seamless integration with all big data tooling and infrastructure via Spark\n",
    "- APIs for Python, Java, Scala, and R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames versus RDDs\n",
    "- Nice API for new users familiar with data frames in other programming languages.\n",
    "- For existing Spark users, the API will make Spark easier to program than using RDDs\n",
    "- For both sets of users, DataFrames will improve performance through intelligent optimizations and code-generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark Shell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the Spark shell:**\n",
    "\n",
    "~~~ bash\n",
    "pyspark\n",
    "~~~\n",
    "\n",
    "Output similar to the following will be displayed, followed by a `>>>` REPL prompt:\n",
    "\n",
    "~~~\n",
    "Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56)\n",
    "[GCC 7.2.0] on linux\n",
    "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    "2018-09-18 17:13:13 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
    "Setting default log level to \"WARN\".\n",
    "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
    "Welcome to\n",
    "      ____              __\n",
    "     / __/__  ___ _____/ /__\n",
    "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
    "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.3.1\n",
    "      /_/\n",
    "\n",
    "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
    "SparkSession available as 'spark'.\n",
    ">>>\n",
    "~~~\n",
    "\n",
    "Read data and convert to Dataset\n",
    "\n",
    "~~~ py\n",
    "df = sqlContext.read.csv(\"/tmp/irmar.csv\", sep=';', header=True)\n",
    "~~~\n",
    "\n",
    "~~~\n",
    ">>> df2.show()\n",
    "+---+--------------------+------------+------+------------+--------+-----+---------+--------+\n",
    "|_c0|                name|       phone|office|organization|position|  hdr|    team1|   team2|\n",
    "+---+--------------------+------------+------+------------+--------+-----+---------+--------+\n",
    "|  0|      Alphonse Paul |+33223235223|   214|          R1|     DOC|False|      EDP|      NA|\n",
    "|  1|        Ammari Zied |+33223235811|   209|          R1|      MC| True|      EDP|      NA|\n",
    ".\n",
    ".\n",
    ".\n",
    "| 18|    Bernier Joachim |+33223237558|   214|          R1|     DOC|False|   ANANUM|      NA|\n",
    "| 19|   Berthelot Pierre |+33223236043|   601|          R1|      PE| True|       GA|      NA|\n",
    "+---+--------------------+------------+------+------------+--------+-----+---------+--------+\n",
    "only showing top 20 rows\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations, Actions, Laziness\n",
    "\n",
    "Like RDDs, DataFrames are lazy. Transformations contribute to the query plan, but they don't execute anything.\n",
    "Actions cause the execution of the query.\n",
    "\n",
    "### Transformation examples\n",
    "- filter\n",
    "- select\n",
    "- drop\n",
    "- intersect \n",
    "- join\n",
    "### Action examples\n",
    "- count \n",
    "- collect \n",
    "- show \n",
    "- head\n",
    "- take"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DataFrame in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "For macosx \n",
    "- Install java-8 (https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)\n",
    "- Install spark with homebrew `brew install apache-spark`\n",
    "- Install pyspark with pip `pip3 install pyspark`\n",
    "\n",
    "\n",
    "```py\n",
    "\n",
    "import os\n",
    "import findspark\n",
    "\n",
    "\n",
    "os.environ[\"JAVA_HOME\"]=\"/Library/Java/JavaVirtualMachines/jdk1.8.0_152.jdk/Contents/Home\"\n",
    "os.environ[\"SPARK_HOME\"]=\"/usr/local/opt/apache-spark/libexec\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/usr/local/bin/python3\"\n",
    "\n",
    "\n",
    "findspark.init()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "# The following three lines are not necessary\n",
    "# in the pyspark shell\n",
    "conf = SparkConf().setAppName(\"people\").setMaster(\"local[*]\") \n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----------+\n",
      "| firstname| lastname|      login|\n",
      "+----------+---------+-----------+\n",
      "|     Simon|     Uzel|     uzel_s|\n",
      "|   Perrine|   Moreau|   moreau_p|\n",
      "|     Elise|    Negri|    negri_e|\n",
      "|   Camille|   Cochet|   cochet_c|\n",
      "|   Nolwenn| Giguelay| giguelay_n|\n",
      "|     Youen|    Meyer|    meyer_y|\n",
      "|    Emilie|  Lacoste|  lacoste_e|\n",
      "|       Pia|  LeBihan|  lebihan_p|\n",
      "|      Yann|    Evain|    evain_y|\n",
      "|   Camille|    Guyon|    guyon_c|\n",
      "|  Mathilde|  LeMener|  lemener_m|\n",
      "|    Gildas| LeGuilly| liguilly_g|\n",
      "|    Pierre| Gardelle| gardelle_p|\n",
      "|Christophe|Boulineau|boulineau_c|\n",
      "|      Omar| Aitichou| aitichou_o|\n",
      "|     Lijun|      Chi|      chi_l|\n",
      "|    Jiawei|      Liu|      lin_j|\n",
      "|     Irvin|Keraudren|keraudren_i|\n",
      "|     Bryan|    Jacob|    jacob_b|\n",
      "|   Raphael| Guillerm| guillerm_r|\n",
      "|     Bruno|Queguiner|queguiner_b|\n",
      "|   Yingshi|     Zeng|     zeng_y|\n",
      "+----------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.json(\"../data/people.json\")\n",
    "\n",
    "df.show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Inference\n",
    "\n",
    "In this exercise, let's explore schema inference. We're going to be using a file called `irmar.txt`. The data is structured, but it has no self-describing schema. And, it's not JSON, so Spark can't infer the schema automatically. Let's create an RDD and look at the first few rows of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphonse Paul;+33223235223;214;R1;DOC;False;EDP;NA\n",
      "Ammari Zied;+33223235811;209;R1;MC;True;EDP;NA\n",
      "André Simon;+33223237555;301;R1;DOC;False;THEO-ERG;NA\n",
      "Angst Jurgen;+33223236519;320;R1;MC;False;PROC-STOC;NA\n",
      "Bailleul Ismaël;+33223236369;302;R1;MC;True;THEO-ERG;NA\n",
      "Baker Mark;+33223236028;835;R1;PR;True;GAN;NA\n",
      "Balac Stephane;+33223236274;110;R1;MC;False;ANANUM;NA\n",
      "Bauer Max;+33223236675;734;R1;MC;False;GAN;NA\n",
      "Bavard Juliette;+33223236724;331;R1;CR;False;GAN;THEO-ERG\n",
      "Beauchard Karine;+33223236164;235;R1;PR;True;ANANUM;NA\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.textFile(\"../data/irmar.csv\")\n",
    "for line in rdd.take(10):\n",
    "  print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on Exercises\n",
    "\n",
    "You can look at the <a href=\"http://spark.apache.org/docs/2.3.1/api/python/index.html\" target=\"_blank\">DataFrames API documentation</a> \n",
    "\n",
    "Let's take a look to file \"/tmp/irmar.csv\". Each line consists \n",
    "of the same information about a person:\n",
    "\n",
    "* name\n",
    "* phone\n",
    "* office\n",
    "* organization\n",
    "* position \n",
    "* hdr\n",
    "* team1\n",
    "* team2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "rdd = sc.textFile(\"../data/irmar.csv\")\n",
    "\n",
    "Person = namedtuple('Person', ['name', 'phone', 'office', 'organization', \n",
    "                               'position', 'hdr', 'team1', 'team2'])\n",
    "def str_to_bool(s):\n",
    "    if s == 'True': return True\n",
    "    return False\n",
    "            \n",
    "def map_to_person(line):\n",
    "    cols = line.split(\";\")\n",
    "    return Person(name         = cols[0],\n",
    "                  phone        = cols[1],\n",
    "                  office       = cols[2],\n",
    "                  organization = cols[3],\n",
    "                  position     = cols[4], \n",
    "                  hdr          = str_to_bool(cols[5]),\n",
    "                  team1        = cols[6],\n",
    "                  team2        = cols[7])\n",
    "    \n",
    "people_rdd = rdd.map(map_to_person)\n",
    "df = people_rdd.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+------+------------+--------+-----+---------+--------+\n",
      "|                name|       phone|office|organization|position|  hdr|    team1|   team2|\n",
      "+--------------------+------------+------+------------+--------+-----+---------+--------+\n",
      "|       Alphonse Paul|+33223235223|   214|          R1|     DOC|false|      EDP|      NA|\n",
      "|         Ammari Zied|+33223235811|   209|          R1|      MC| true|      EDP|      NA|\n",
      "|         André Simon|+33223237555|   301|          R1|     DOC|false| THEO-ERG|      NA|\n",
      "|        Angst Jurgen|+33223236519|   320|          R1|      MC|false|PROC-STOC|      NA|\n",
      "|     Bailleul Ismaël|+33223236369|   302|          R1|      MC| true| THEO-ERG|      NA|\n",
      "|          Baker Mark|+33223236028|   835|          R1|      PR| true|      GAN|      NA|\n",
      "|      Balac Stephane|+33223236274|   110|          R1|      MC|false|   ANANUM|      NA|\n",
      "|           Bauer Max|+33223236675|   734|          R1|      MC|false|      GAN|      NA|\n",
      "|     Bavard Juliette|+33223236724|   331|          R1|      CR|false|      GAN|THEO-ERG|\n",
      "|    Beauchard Karine|+33223236164|   235|          R1|      PR| true|   ANANUM|      NA|\n",
      "|        Bekka Bachir|+33223235779|   307|          R1|      PR| true| THEO-ERG|      NA|\n",
      "|         Bekka Karim|+33223236180|   615|          R1|      MC|false|      G&S|      NA|\n",
      "|      Belgacem Maher|+33223236670|    NA|         EXT|     DOC|false|   ANANUM|      NA|\n",
      "|    Bellis Alexandre|+33223236696|   634|          R1|     DOC|false|      GAN|      NA|\n",
      "|     Belmiloudi Aziz|+33223238646|    NA|        INSA|      MC| true|   ANANUM|      NA|\n",
      "|     Ben Elouefi Rim|+33223236670|    NA|         EXT|     DOC|false|     STAT|      NA|\n",
      "|   Benasseni Jacques|+33299141822|    NA|          R2|      PR| true|     STAT|      NA|\n",
      "|Bennani-Dosse Moh...|+33299141796|    NA|          R2|      MC|false|     STAT|      NA|\n",
      "|     Bernier Joachim|+33223237558|   214|          R1|     DOC|false|   ANANUM|      NA|\n",
      "|    Berthelot Pierre|+33223236043|   601|          R1|      PE| true|       GA|      NA|\n",
      "+--------------------+------------+------+------------+--------+-----+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- phone: string (nullable = true)\n",
      " |-- office: string (nullable = true)\n",
      " |-- organization: string (nullable = true)\n",
      " |-- position: string (nullable = true)\n",
      " |-- hdr: boolean (nullable = true)\n",
      " |-- team1: string (nullable = true)\n",
      " |-- team2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, phone: string, office: string, organization: string, position: string, hdr: boolean, team1: string, team2: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, position: string, organization: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(df[\"name\"], df[\"position\"], df[\"organization\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------------+\n",
      "|                name|position|organization|\n",
      "+--------------------+--------+------------+\n",
      "|       Alphonse Paul|     DOC|          R1|\n",
      "|         Ammari Zied|      MC|          R1|\n",
      "|         André Simon|     DOC|          R1|\n",
      "|        Angst Jurgen|      MC|          R1|\n",
      "|     Bailleul Ismaël|      MC|          R1|\n",
      "|          Baker Mark|      PR|          R1|\n",
      "|      Balac Stephane|      MC|          R1|\n",
      "|           Bauer Max|      MC|          R1|\n",
      "|     Bavard Juliette|      CR|          R1|\n",
      "|    Beauchard Karine|      PR|          R1|\n",
      "|        Bekka Bachir|      PR|          R1|\n",
      "|         Bekka Karim|      MC|          R1|\n",
      "|      Belgacem Maher|     DOC|         EXT|\n",
      "|    Bellis Alexandre|     DOC|          R1|\n",
      "|     Belmiloudi Aziz|      MC|        INSA|\n",
      "|     Ben Elouefi Rim|     DOC|         EXT|\n",
      "|   Benasseni Jacques|      PR|          R2|\n",
      "|Bennani-Dosse Moh...|      MC|          R2|\n",
      "|     Bernier Joachim|     DOC|          R1|\n",
      "|    Berthelot Pierre|      PE|          R1|\n",
      "+--------------------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df[\"name\"], df[\"position\"], df[\"organization\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+------+------------+--------+-----+---------+-----+\n",
      "|                name|       phone|office|organization|position|  hdr|    team1|team2|\n",
      "+--------------------+------------+------+------------+--------+-----+---------+-----+\n",
      "|   Benasseni Jacques|+33299141822|    NA|          R2|      PR| true|     STAT|   NA|\n",
      "|Bennani-Dosse Moh...|+33299141796|    NA|          R2|      MC|false|     STAT|   NA|\n",
      "|Cornillon Pierre-...|+33299141819|    NA|          R2|      MC|false|     STAT|   NA|\n",
      "|     Fromont Magalie|+33299053264|    NA|          R2|      PR| true|     STAT|   NA|\n",
      "|Giacofci Joyce Ma...|+33299141800|    NA|          R2|      MC|false|     STAT|   NA|\n",
      "|Klutchnikoff Nicolas|+33299141819|    NA|          R2|      MC|false|     STAT|   NA|\n",
      "|     Le Guevel Ronan|+33299141800|    NA|          R2|      MC|false|PROC-STOC| STAT|\n",
      "|           Mom Alain|+33299141808|    NA|          R2|      MC|false|     STAT|   NA|\n",
      "|        Morvan Marie|+33223236670|    NA|          R2|     DOC|false|     STAT|   NA|\n",
      "|     Pelletier Bruno|+33299141807|    NA|          R2|      PR| true|     STAT|   NA|\n",
      "|    Rouviere Laurent|+33299141804|    NA|          R2|      MC|false|     STAT|   NA|\n",
      "+--------------------+------------+------+------------+--------+-----+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"organization\"] == \"R2\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter + select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.filter(df[\"organization\"] == \"R2\").select(df['name'],df['team1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|                name|    team1|\n",
      "+--------------------+---------+\n",
      "|   Benasseni Jacques|     STAT|\n",
      "|Bennani-Dosse Moh...|     STAT|\n",
      "|Cornillon Pierre-...|     STAT|\n",
      "|     Fromont Magalie|     STAT|\n",
      "|Giacofci Joyce Ma...|     STAT|\n",
      "|Klutchnikoff Nicolas|     STAT|\n",
      "|     Le Guevel Ronan|PROC-STOC|\n",
      "|           Mom Alain|     STAT|\n",
      "|        Morvan Marie|     STAT|\n",
      "|     Pelletier Bruno|     STAT|\n",
      "|    Rouviere Laurent|     STAT|\n",
      "+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### orderBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                name|position|\n",
      "+--------------------+--------+\n",
      "|        Morvan Marie|     DOC|\n",
      "|           Mom Alain|      MC|\n",
      "|    Rouviere Laurent|      MC|\n",
      "|     Le Guevel Ronan|      MC|\n",
      "|Klutchnikoff Nicolas|      MC|\n",
      "|Giacofci Joyce Ma...|      MC|\n",
      "|Cornillon Pierre-...|      MC|\n",
      "|Bennani-Dosse Moh...|      MC|\n",
      "|     Pelletier Bruno|      PR|\n",
      "|     Fromont Magalie|      PR|\n",
      "|   Benasseni Jacques|      PR|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.filter(df[\"organization\"] == \"R2\")\n",
    "   .select(df[\"name\"],df[\"position\"])\n",
    "   .orderBy(\"position\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.group.GroupedData at 0x10880a450>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(df[\"hdr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|  hdr|count|\n",
      "+-----+-----+\n",
      "| true|  103|\n",
      "|false|  141|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(df[\"hdr\"]).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: Don't confuse GroupedData.count() with DataFrame.count(). GroupedData.count() is not an action. DataFrame.count() is an action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df[\"hdr\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|         Ammari Zied|\n",
      "|     Bailleul Ismaël|\n",
      "|          Baker Mark|\n",
      "|    Beauchard Karine|\n",
      "|        Bekka Bachir|\n",
      "|     Belmiloudi Aziz|\n",
      "|   Benasseni Jacques|\n",
      "|    Berthelot Pierre|\n",
      "|       Bourqui David|\n",
      "|Breton Jean-Chris...|\n",
      "|         Briane Marc|\n",
      "|        Cadre Benoît|\n",
      "|       Caloz Gabriel|\n",
      "|        Cantat Serge|\n",
      "|       Caruso Xavier|\n",
      "|   Castella Francois|\n",
      "|       Causeur David|\n",
      "|   Cerveau Dominique|\n",
      "|   Chartier Philippe|\n",
      "|   Chauvet Guillaume|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['hdr']).select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|organization|count|\n",
      "+------------+-----+\n",
      "|         ENS|    3|\n",
      "|        CNRS|    6|\n",
      "|        INSA|   19|\n",
      "|          R2|   11|\n",
      "|       INRIA|    5|\n",
      "|        AGRO|    5|\n",
      "|         EXT|    2|\n",
      "|          R1|  193|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df[\"organization\"]).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "- How many teachers from INSA (PR+MC) ?\n",
    "- How many MC in STATS team ?\n",
    "- How many MC+CR with HDR ?\n",
    "- What is the ratio of student supervision (DOC / HDR) ?\n",
    "- List number of people for every organization ?\n",
    "- List number of HDR people for every team ?\n",
    "- Which team contains most HDR ?\n",
    "- List number of DOC students for every organization ?\n",
    "- Which team contains most DOC ?\n",
    "- List people from CNRS that are neither CR nor DR ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"organization\").filter(df[\"organization\"]==\"INSA\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.select([\"position\", \"team1\", \"team2\"])\n",
    " .filter((df[\"team1\"]==\"STAT\") | (df[\"team2\"]==\"STAT\"))\n",
    " .filter(df[\"position\"] == \"MC\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.select(df[\"position\"], df[\"hdr\"])\n",
    " .filter((df[\"position\"]==\"MC\") | (df[\"position\"]==\"CR\"))\n",
    " .filter(df[\"hdr\"]).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6019417475728155"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.select(df[\"position\"]).filter(df[\"position\"]==\"DOC\").count() /\n",
    " df.select(df[\"hdr\"]).filter(df[\"hdr\"]).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EDP', 11),\n",
       " ('THEO-ERG', 14),\n",
       " ('STAT', 14),\n",
       " ('G&S', 9),\n",
       " ('MECA', 6),\n",
       " ('GAN', 9),\n",
       " ('ANANUM', 21),\n",
       " ('GA', 8),\n",
       " ('PROC-STOC', 7),\n",
       " ('GAE', 8),\n",
       " ('IREM', 2),\n",
       " ('ADM', 1)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.select([\"hdr\", \"team1\", \"team2\"])\n",
    " .filter(\"hdr\")\n",
    " .rdd.flatMap(lambda row: (row.team1, row.team2))\n",
    " .filter(lambda v : v != 'NA')\n",
    " .map(lambda row : (row,1))\n",
    " .reduceByKey(lambda a, b:a+b)\n",
    " .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EDP', 7),\n",
       " ('THEO-ERG', 8),\n",
       " ('STAT', 9),\n",
       " ('G&S', 2),\n",
       " ('MECA', 4),\n",
       " ('ANANUM', 14),\n",
       " ('GAN', 8),\n",
       " ('GAE', 4),\n",
       " ('PROC-STOC', 8),\n",
       " ('GA', 4)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.select([\"position\", \"team1\", \"team2\"])\n",
    " .filter(df.position==\"DOC\")\n",
    " .rdd.flatMap(lambda row: [row.team1, row.team2])\n",
    " .filter(lambda v : v != 'NA')\n",
    " .map(lambda row : (row,1))\n",
    " .reduceByKey(lambda a, b:a+b)\n",
    " .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = (df.select([\"position\", \"team1\"])\n",
    " .groupBy(\"team1\")\n",
    " .count()\n",
    ")\n",
    "\n",
    "df2 = (df.select([\"position\", \"team2\"])\n",
    " .filter(df.team2 != \"NA\")\n",
    " .groupBy(\"team2\")\n",
    " .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+---------+-----+-----+\n",
      "|    team1|count|    team2|count|total|\n",
      "+---------+-----+---------+-----+-----+\n",
      "|      EDP|   18|      EDP|    2|   20|\n",
      "|      G&S|   11|      G&S|    1|   12|\n",
      "| THEO-ERG|   21| THEO-ERG|    7|   28|\n",
      "|PROC-STOC|   17|PROC-STOC|    3|   20|\n",
      "|     STAT|   38|     STAT|    1|   39|\n",
      "|       GA|   13|       GA|    4|   17|\n",
      "+---------+-----+---------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df1.join(df2, df1.team1 == df2.team2).withColumn(\"total\", df1[\"count\"]+df2[\"count\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|      Belgacem Maher|\n",
      "|     Bernier Joachim|\n",
      "|       Calvez Adrien|\n",
      "|        Corre Samuel|\n",
      "|      Dao Manh Khang|\n",
      "|       Doli Valentin|\n",
      "|     Fontaine Marine|\n",
      "|       Horsin Romain|\n",
      "| Joannopoulos Emilie|\n",
      "|     Le Balc'h Kevin|\n",
      "|        Moitier Zoïs|\n",
      "|Nguyen Thi-Hoai-T...|\n",
      "|      Rosello Angelo|\n",
      "|      Tusseau Maxime|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.filter((df.position==\"DOC\") & (df.team1 == \"ANANUM\"))\n",
    " .select(\"name\")\n",
    " .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|organization|count|\n",
      "+------------+-----+\n",
      "|         ENS|    3|\n",
      "|        CNRS|    6|\n",
      "|        INSA|   19|\n",
      "|          R2|   11|\n",
      "|       INRIA|    5|\n",
      "|        AGRO|    5|\n",
      "|         EXT|    2|\n",
      "|          R1|  193|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select(\"organization\")\n",
    " .groupby(\"organization\").count().show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+--------+\n",
      "|               name|organization|position|\n",
      "+-------------------+------------+--------+\n",
      "|    Bavard Juliette|          R1|      CR|\n",
      "|Bonthonneau Yannick|          R1|      CR|\n",
      "|       Cantat Serge|          R1|      DR|\n",
      "|      Caruso Xavier|          R1|      CR|\n",
      "|     Cérou Frédéric|       INRIA|      CR|\n",
      "|  Chartier Philippe|          R1|      DR|\n",
      "|        Coulon Rémi|          R1|      CR|\n",
      "|Crouseilles Nicolas|          R1|      CR|\n",
      "|      Dauge Monique|          R1|      DR|\n",
      "|    Duchene Vincent|          R1|      CR|\n",
      "|     Erhel Jocelyne|          R1|      DR|\n",
      "|         Faou Erwan|          R1|      DR|\n",
      "|        Gros Michel|          R1|      CR|\n",
      "|       Héas Patrick|          R1|      CR|\n",
      "|      Herzet Cedric|          R1|      CR|\n",
      "|    Kleptsyn Victor|          R1|      CR|\n",
      "|  Le Gland François|       INRIA|      DR|\n",
      "|     Lemou Mohammed|          R1|      DR|\n",
      "|        Loray Frank|          R1|      DR|\n",
      "|      Memin Etienne|       INRIA|      DR|\n",
      "+-------------------+------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select([\"name\",\"organization\",\"position\"])\n",
    " .filter((df.position == \"DR\") | (df.position == \"CR\"))\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------+\n",
      "|                name|organization|position|\n",
      "+--------------------+------------+--------+\n",
      "|       Collin Maryse|        CNRS|      IR|\n",
      "|        Garo Olivier|        CNRS|      IE|\n",
      "|Guillemer Marie-A...|        CNRS|      AI|\n",
      "|          Guiny Aude|        CNRS|      TC|\n",
      "|       Navaro Pierre|        CNRS|      IR|\n",
      "|    Rousseaux Hélène|        CNRS|      TC|\n",
      "+--------------------+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select([\"name\",\"organization\",\"position\"])\n",
    " .filter(df.organization == \"CNRS\")\n",
    " .filter((df.position != \"DR\") | (df.position != \"CR\"))\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,../src//py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
